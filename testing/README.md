# Testing - Suite de Pruebas para SISTAOUT

Este directorio contiene una suite completa de pruebas para el sistema SISTAOUT, dise帽ada para asegurar la calidad, funcionalidad y estabilidad del software.

##  Estructura de Pruebas

### 1. **Pruebas de Regresi贸n** (`test_regression.py`)
Verifican que los cambios recientes no hayan roto funcionalidades existentes que anteriormente funcionaban correctamente.

**Cubre:**
- Procesamiento de datos
- Detecci贸n de outliers (IQR, Z-Score, MAD)
- Tests estad铆sticos (Mann-Whitney)
- Estad铆sticas descriptivas
- Clustering
- Regresi贸n log铆stica
- Modelos predictivos
- Estructura de endpoints API

### 2. **Pruebas Funcionales** (`test_functional.py`)
Verifican que cada funci贸n realiza correctamente su tarea espec铆fica seg煤n los requisitos del sistema.

**Cubre:**
- Subida de datasets
- Detecci贸n de outliers con diferentes m茅todos
- Tests estad铆sticos
- An谩lisis descriptivo
- Clustering (K-means)
- Regresi贸n log铆stica
- Modelos predictivos (Random Forest)
- Detecci贸n de tipos de variables
- Limpieza de datos
- Estrategias de combinaci贸n de outliers

### 3. **Pruebas de Caja Blanca** (`test_whitebox.py`)
Verifican el funcionamiento interno del c贸digo, incluyendo rutas de ejecuci贸n, condiciones, bucles y l贸gica interna.

**Cubre:**
- L贸gica interna de c谩lculos (IQR, Z-Score, MAD)
- Casos extremos (DataFrames vac铆os, valores 煤nicos, valores iguales)
- Manejo de valores NaN
- Cobertura de condiciones y bucles
- Manejo de errores
- L贸gica interna de procesamiento
- L贸gica interna de tests estad铆sticos
- L贸gica interna de clustering
- L贸gica interna de entrenamiento de modelos

### 4. **Pruebas de Caja Negra** (`test_blackbox.py`)
Verifican la funcionalidad del sistema desde la perspectiva del usuario final, sin conocer los detalles internos de implementaci贸n.

**Cubre:**
- Health check del API
- Subida de datasets
- Obtenci贸n de lista de datasets
- Detecci贸n de outliers
- Manejo de entradas inv谩lidas
- Manejo de par谩metros faltantes
- Consistencia de formato de respuestas
- Claridad de mensajes de error
- Manejo de timeouts
- Solicitudes concurrentes
- Integridad de datos
- Headers CORS
- Validaci贸n de tipos de contenido

##  Instalaci贸n y Configuraci贸n

### Requisitos Previos

1. **Python 3.8+** con las siguientes dependencias:
   ```bash
   pip install pytest pytest-cov requests pandas numpy
   ```

2. **Servidor ejecut谩ndose** (para pruebas de caja negra):
   ```bash
   python main.py
   ```

### Estructura de Directorios

```
testing/
 __init__.py
 test_regression.py      # Pruebas de regresi贸n
 test_functional.py      # Pruebas funcionales
 test_whitebox.py        # Pruebas de caja blanca
 test_blackbox.py        # Pruebas de caja negra
 run_all_tests.py        # Script para ejecutar todas las pruebas
 README.md               # Este archivo
```

##  Uso

### Ejecutar Todas las Pruebas

```bash
# Desde el directorio ra铆z del proyecto
py testing/run_all_tests.py
```

### Ejecutar Pruebas con el Servidor Corriendo

Si tienes el servidor ejecut谩ndose en `http://localhost:8000`, puedes usar los scripts helper:

**Windows (PowerShell):**
```powershell
.\testing\run_tests_with_server.ps1
```

**Linux/Mac (Bash):**
```bash
bash testing/run_tests_with_server.sh
```

O manualmente:

1. **Aseg煤rate de que el servidor est茅 corriendo:**
   ```bash
   python main.py
   ```

2. **En otra terminal, ejecuta las pruebas:**
   ```bash
   # Todas las pruebas (incluyendo caja negra)
   python testing/run_all_tests.py --verbose
   
   # Solo pruebas de caja negra (requieren servidor)
   python testing/run_all_tests.py --type blackbox --verbose
   ```

### Ejecutar un Tipo Espec铆fico de Pruebas

```bash
# Solo pruebas de regresi贸n
py testing/run_all_tests.py --type regression

# Solo pruebas funcionales
py testing/run_all_tests.py --type functional

# Solo pruebas de caja blanca
py testing/run_all_tests.py --type whitebox

# Solo pruebas de caja negra
py testing/run_all_tests.py --type blackbox
```

### Ejecutar con Salida Detallada

```bash
py testing/run_all_tests.py --verbose
```

### Ejecutar con Reporte de Cobertura

```bash
py testing/run_all_tests.py --coverage
```

##  Sistema de Reportes

El sistema genera reportes autom谩ticamente en m煤ltiples formatos para facilitar el an谩lisis de resultados.

### Generaci贸n Autom谩tica de Reportes

Por defecto, al ejecutar las pruebas se generan reportes en la carpeta `testing/reports/`:

```bash
# Generar reportes (por defecto)
py testing/run_all_tests.py --type blackbox

# Ejecutar sin generar reportes
py testing/run_all_tests.py --type blackbox --no-reports
```

### Tipos de Reportes Generados

1. **Reportes HTML** (`report_<tipo>_<timestamp>.html`)
   - Reportes visuales interactivos con detalles de cada prueba
   - Incluyen informaci贸n sobre pruebas pasadas, fallidas y omitidas
   - Contienen trazas de error completas para pruebas fallidas
   - Se pueden abrir directamente en el navegador

2. **Reportes JSON** (`report_<tipo>_<timestamp>.json`)
   - Formato estructurado para procesamiento automatizado
   - Incluyen estad铆sticas detalladas por prueba
   - tiles para integraci贸n con CI/CD

3. **Reporte Consolidado** (`report_consolidado_<timestamp>.txt` y `.json`)
   - Resumen general de todas las pruebas ejecutadas
   - Estad铆sticas agregadas por tipo de prueba
   - Tasa de 茅xito general

### Visualizar Reportes

#### Ver el Reporte M谩s Reciente

```bash
# Mostrar el reporte m谩s reciente en consola
py testing/view_reports.py --latest

# O simplemente
py testing/view_reports.py
```

#### Listar Todos los Reportes Disponibles

```bash
py testing/view_reports.py --list
```

#### Ver un Reporte Espec铆fico

```bash
py testing/view_reports.py --file testing/reports/report_consolidado_20250102_123456.json
```

### Estructura de Reportes

```
testing/
 reports/
     report_regression_20250102_123456.html
     report_regression_20250102_123456.json
     report_functional_20250102_123456.html
     report_functional_20250102_123456.json
     report_whitebox_20250102_123456.html
     report_whitebox_20250102_123456.json
     report_blackbox_20250102_123456.html
     report_blackbox_20250102_123456.json
     report_consolidado_20250102_123456.txt
     report_consolidado_20250102_123456.json
     coverage/  (si se usa --coverage)
         index.html
```

### Interpretaci贸n de Reportes

#### Reporte Consolidado

El reporte consolidado muestra:

- **Resumen General:**
  - Total de pruebas ejecutadas
  - Pruebas pasadas, fallidas y omitidas
  - Tasa de 茅xito general
  - Estado general (PASO/FALLO)

- **Detalle por Tipo de Prueba:**
  - Estado individual de cada tipo
  - Estad铆sticas espec铆ficas por tipo
  - Tasa de 茅xito por tipo

#### Reportes HTML

Los reportes HTML incluyen:

- Lista completa de todas las pruebas ejecutadas
- Estado de cada prueba (PASSED/FAILED/SKIPPED)
- Tiempo de ejecuci贸n de cada prueba
- Trazas de error completas para pruebas fallidas
- Estad铆sticas resumidas al inicio

#### Reportes JSON

Los reportes JSON contienen:

```json
{
  "timestamp": "20250102_123456",
  "date": "2025-01-02T12:34:56",
  "results": {
    "regression": {
      "passed": 11,
      "failed": 0,
      "skipped": 0,
      "total": 11,
      "success": true,
      "test_type": "regression",
      "description": "Pruebas de Regresi贸n"
    }
  },
  "summary": {
    "total_passed": 52,
    "total_failed": 0,
    "total_skipped": 0,
    "total_tests": 52,
    "overall_success": true,
    "success_rate": 100.0
  }
}
```

### Ejecutar Pruebas Individuales con pytest

```bash
# Ejecutar un archivo espec铆fico
pytest testing/test_regression.py -v

# Ejecutar una clase espec铆fica
pytest testing/test_regression.py::TestRegression -v

# Ejecutar un test espec铆fico
pytest testing/test_regression.py::TestRegression::test_data_processing_regression -v
```

##  Interpretaci贸n de Resultados

### C贸digos de Salida

- **0**: Todas las pruebas pasaron exitosamente
- **1**: Una o m谩s pruebas fallaron

### Tipos de Aserciones

Las pruebas utilizan diferentes tipos de aserciones seg煤n el contexto:

- **Aserciones de existencia**: Verifican que los objetos existen
- **Aserciones de tipo**: Verifican que los tipos de datos son correctos
- **Aserciones de valor**: Verifican que los valores son los esperados
- **Aserciones de estructura**: Verifican que las estructuras de datos son correctas

##  Mantenimiento

### Agregar Nuevas Pruebas

1. **Identificar el 谩rea a probar**: Determinar si es regresi贸n, funcional, caja blanca o caja negra
2. **Crear el test**: Agregar un nuevo m茅todo `test_*` en la clase correspondiente
3. **Usar fixtures**: Aprovechar los fixtures existentes para datos de prueba
4. **Documentar**: Agregar docstrings explicando qu茅 prueba el test

### Ejemplo de Nuevo Test

```python
def test_nueva_funcionalidad(self, analysis_viz, sample_data):
    """Verificar que la nueva funcionalidad funciona correctamente"""
    # Preparar datos
    # Ejecutar funci贸n
    results = analysis_viz.nueva_funcionalidad(sample_data)
    
    # Verificar resultados
    assert results is not None
    assert 'expected_key' in results
```

## 锔 Notas Importantes

### Pruebas de Caja Negra

Las pruebas de caja negra (`test_blackbox.py`) requieren que el servidor est茅 ejecut谩ndose. Si el servidor no est谩 disponible, estas pruebas se saltar谩n autom谩ticamente.

Para ejecutar pruebas de caja negra:

1. Iniciar el servidor en una terminal:
   ```bash
   python main.py
   ```

2. En otra terminal, ejecutar las pruebas:
   ```bash
   python testing/run_all_tests.py --type blackbox
   ```

### Datos de Prueba

Las pruebas utilizan datos sint茅ticos generados con `numpy.random` con una semilla fija (42) para garantizar reproducibilidad.

### Fixtures

Los fixtures de pytest proporcionan:
- `sample_data`: DataFrame con datos de muestra
- `temp_dir`: Directorio temporal para archivos de prueba
- `data_processor`: Instancia de DataProcessor
- `outlier_detector`: Instancia de OutlierDetector
- `analysis_viz`: Instancia de AnalysisAndVisualization

##  M茅tricas de Calidad

### Cobertura de C贸digo

Para generar un reporte de cobertura:

```bash
python testing/run_all_tests.py --coverage
```

El reporte HTML se generar谩 en `htmlcov/index.html`.

### Objetivos de Cobertura

- **M铆nimo recomendado**: 70% de cobertura
- **Ideal**: 80%+ de cobertura
- **Cr铆tico**: 90%+ para m贸dulos cr铆ticos

##  Soluci贸n de Problemas

### Error: "ModuleNotFoundError"

Aseg煤rate de estar ejecutando las pruebas desde el directorio ra铆z del proyecto y que todas las dependencias est茅n instaladas.

### Error: "ConnectionError" en pruebas de caja negra

Aseg煤rate de que el servidor est茅 ejecut谩ndose antes de ejecutar las pruebas de caja negra.

### Error: "FileNotFoundError"

Verifica que los archivos de prueba existan y que las rutas sean correctas.

##  Referencias

- [Documentaci贸n de pytest](https://docs.pytest.org/)
- [Documentaci贸n de pytest-cov](https://pytest-cov.readthedocs.io/)
- [Best Practices for Testing](https://docs.python.org/3/library/unittest.html)

##  Contribuci贸n

Al agregar nuevas funcionalidades al sistema, aseg煤rate de:

1. Agregar pruebas correspondientes
2. Ejecutar todas las pruebas antes de hacer commit
3. Verificar que la cobertura de c贸digo no disminuya
4. Documentar cualquier cambio en los requisitos de prueba

---

**ltima actualizaci贸n**: Diciembre 2024

